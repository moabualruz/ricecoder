{
  "$schema": "./models.schema.json",
  "version": "1.0.0",
  "updated_at": "2025-12-27T04:30:00Z",
  "priority_models": [
    "gpt-5",
    "claude-sonnet-4",
    "gpt-4-turbo",
    "claude-3-opus-20250219",
    "gemini-1.5-pro",
    "gpt-4o",
    "gpt-4",
    "claude-3-5-sonnet-20241022",
    "gpt-3.5-turbo"
  ],
  "providers": {
    "anthropic": {
      "name": "Anthropic",
      "base_url": "https://api.anthropic.com/v1",
      "env": ["ANTHROPIC_API_KEY"],
      "models": [
        {
          "id": "claude-3-opus-20250219",
          "name": "Claude 3 Opus",
          "context_window": 200000,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "code", "streaming", "vision"],
          "pricing": {
            "input_per_1k": 0.015,
            "output_per_1k": 0.075,
            "cache_read_per_1k": 0.0015,
            "cache_write_per_1k": 0.01875
          },
          "is_free": false
        },
        {
          "id": "claude-3-5-sonnet-20241022",
          "name": "Claude 3.5 Sonnet",
          "context_window": 200000,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming", "vision"],
          "pricing": {
            "input_per_1k": 0.003,
            "output_per_1k": 0.015,
            "cache_read_per_1k": 0.0003,
            "cache_write_per_1k": 0.00375
          },
          "is_free": false
        },
        {
          "id": "claude-3-5-haiku-20241022",
          "name": "Claude 3.5 Haiku",
          "context_window": 200000,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming", "vision"],
          "pricing": {
            "input_per_1k": 0.0008,
            "output_per_1k": 0.004,
            "cache_read_per_1k": 0.00008,
            "cache_write_per_1k": 0.0005
          },
          "is_free": false
        },
        {
          "id": "claude-3-haiku-20240307",
          "name": "Claude 3 Haiku",
          "context_window": 200000,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "code", "streaming", "vision"],
          "pricing": {
            "input_per_1k": 0.00025,
            "output_per_1k": 0.00125,
            "cache_read_per_1k": 0.000025,
            "cache_write_per_1k": 0.0003125
          },
          "is_free": false
        }
      ]
    },
    "openai": {
      "name": "OpenAI",
      "base_url": "https://api.openai.com/v1",
      "env": ["OPENAI_API_KEY"],
      "models": [
        {
          "id": "gpt-4",
          "name": "GPT-4",
          "context_window": 8192,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming"],
          "pricing": {
            "input_per_1k": 0.03,
            "output_per_1k": 0.06
          },
          "is_free": false
        },
        {
          "id": "gpt-4-32k",
          "name": "GPT-4 32K",
          "context_window": 32768,
          "max_output_tokens": 32768,
          "capabilities": ["chat", "code", "streaming"],
          "pricing": {
            "input_per_1k": 0.06,
            "output_per_1k": 0.12
          },
          "is_free": false
        },
        {
          "id": "gpt-4-turbo",
          "name": "GPT-4 Turbo",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "code", "streaming", "vision"],
          "pricing": {
            "input_per_1k": 0.01,
            "output_per_1k": 0.03
          },
          "is_free": false
        },
        {
          "id": "gpt-4o",
          "name": "GPT-4o",
          "context_window": 128000,
          "max_output_tokens": 16384,
          "capabilities": ["chat", "code", "streaming", "vision", "function_calling"],
          "pricing": {
            "input_per_1k": 0.0025,
            "output_per_1k": 0.01
          },
          "is_free": false
        },
        {
          "id": "gpt-4o-mini",
          "name": "GPT-4o Mini",
          "context_window": 128000,
          "max_output_tokens": 16384,
          "capabilities": ["chat", "code", "streaming", "vision"],
          "pricing": {
            "input_per_1k": 0.00015,
            "output_per_1k": 0.0006
          },
          "is_free": false
        },
        {
          "id": "gpt-3.5-turbo",
          "name": "GPT-3.5 Turbo",
          "context_window": 4096,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "code", "streaming"],
          "pricing": {
            "input_per_1k": 0.0005,
            "output_per_1k": 0.0015
          },
          "is_free": false
        },
        {
          "id": "gpt-3.5-turbo-16k",
          "name": "GPT-3.5 Turbo 16K",
          "context_window": 16384,
          "max_output_tokens": 16384,
          "capabilities": ["chat", "code", "streaming"],
          "pricing": {
            "input_per_1k": 0.003,
            "output_per_1k": 0.004
          },
          "is_free": false
        },
        {
          "id": "o1-preview",
          "name": "O1 Preview",
          "context_window": 128000,
          "max_output_tokens": 32768,
          "capabilities": ["chat", "code", "streaming"],
          "pricing": {
            "input_per_1k": 0.015,
            "output_per_1k": 0.06
          },
          "is_free": false
        },
        {
          "id": "o1-mini",
          "name": "O1 Mini",
          "context_window": 128000,
          "max_output_tokens": 65536,
          "capabilities": ["chat", "code", "streaming"],
          "pricing": {
            "input_per_1k": 0.003,
            "output_per_1k": 0.012
          },
          "is_free": false
        },
        {
          "id": "o3-mini",
          "name": "O3 Mini",
          "context_window": 200000,
          "max_output_tokens": 100000,
          "capabilities": ["chat", "code", "streaming"],
          "pricing": {
            "input_per_1k": 0.0011,
            "output_per_1k": 0.0044
          },
          "is_free": false
        }
      ]
    },
    "google": {
      "name": "Google",
      "base_url": "https://generativelanguage.googleapis.com/v1beta",
      "env": ["GOOGLE_API_KEY"],
      "models": [
        {
          "id": "gemini-2.0-flash",
          "name": "Gemini 2.0 Flash",
          "context_window": 1000000,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming", "vision"],
          "pricing": {
            "input_per_1k": 0.0,
            "output_per_1k": 0.0
          },
          "is_free": true
        },
        {
          "id": "gemini-1.5-pro",
          "name": "Gemini 1.5 Pro",
          "context_window": 2000000,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming", "vision"],
          "pricing": {
            "input_per_1k": 0.00125,
            "output_per_1k": 0.005
          },
          "is_free": false
        },
        {
          "id": "gemini-1.5-flash",
          "name": "Gemini 1.5 Flash",
          "context_window": 1000000,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming", "vision"],
          "pricing": {
            "input_per_1k": 0.000075,
            "output_per_1k": 0.0003
          },
          "is_free": false
        },
        {
          "id": "gemini-1.0-pro",
          "name": "Gemini 1.0 Pro",
          "context_window": 32000,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming"],
          "pricing": {
            "input_per_1k": 0.0005,
            "output_per_1k": 0.0015
          },
          "is_free": false
        }
      ]
    },
    "qwen": {
      "name": "Qwen (Alibaba)",
      "base_url": "https://dashscope.aliyuncs.com/api/v1",
      "env": ["QWEN_API_KEY", "DASHSCOPE_API_KEY"],
      "models": [
        {
          "id": "qwen3-235b-a22b",
          "name": "Qwen3 235B",
          "context_window": 131072,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming"],
          "is_free": false
        },
        {
          "id": "qwen3-32b",
          "name": "Qwen3 32B",
          "context_window": 131072,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming"],
          "is_free": false
        },
        {
          "id": "qwen3-8b",
          "name": "Qwen3 8B",
          "context_window": 131072,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming"],
          "is_free": false
        },
        {
          "id": "qwen2.5-coder-32b-instruct",
          "name": "Qwen2.5 Coder 32B",
          "context_window": 131072,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming"],
          "is_free": false
        },
        {
          "id": "qwen-max",
          "name": "Qwen Max",
          "context_window": 32768,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming"],
          "pricing": {
            "input_per_1k": 0.0024,
            "output_per_1k": 0.0096
          },
          "is_free": false
        },
        {
          "id": "qwen-plus",
          "name": "Qwen Plus",
          "context_window": 131072,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming"],
          "pricing": {
            "input_per_1k": 0.0008,
            "output_per_1k": 0.002
          },
          "is_free": false
        },
        {
          "id": "qwen-turbo",
          "name": "Qwen Turbo",
          "context_window": 131072,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming"],
          "pricing": {
            "input_per_1k": 0.0003,
            "output_per_1k": 0.0006
          },
          "is_free": false
        }
      ]
    },
    "ollama": {
      "name": "Ollama (Local)",
      "base_url": "http://localhost:11434/api",
      "env": [],
      "models": [
        {
          "id": "mistral",
          "name": "Mistral 7B",
          "context_window": 8192,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "code", "streaming"],
          "is_free": true
        },
        {
          "id": "llama2",
          "name": "Llama 2",
          "context_window": 4096,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "code", "streaming"],
          "is_free": true
        },
        {
          "id": "neural-chat",
          "name": "Neural Chat",
          "context_window": 4096,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "streaming"],
          "is_free": true
        }
      ]
    },
    "cohere": {
      "name": "Cohere",
      "base_url": "https://api.cohere.ai/v1",
      "env": ["COHERE_API_KEY"],
      "models": [
        {
          "id": "command",
          "name": "Command",
          "context_window": 4096,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "streaming"],
          "pricing": {
            "input_per_1k": 0.015,
            "output_per_1k": 0.015
          },
          "is_free": false
        },
        {
          "id": "command-light",
          "name": "Command Light",
          "context_window": 4096,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "streaming"],
          "pricing": {
            "input_per_1k": 0.015,
            "output_per_1k": 0.015
          },
          "is_free": false
        }
      ]
    },
    "together": {
      "name": "Together AI",
      "base_url": "https://api.together.xyz/v1",
      "env": ["TOGETHER_API_KEY"],
      "models": [
        {
          "id": "meta-llama/Llama-2-70b-chat-hf",
          "name": "Llama 2 70B Chat",
          "context_window": 4096,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "streaming"],
          "pricing": {
            "input_per_1k": 0.0009,
            "output_per_1k": 0.0009
          },
          "is_free": false
        },
        {
          "id": "mistralai/Mistral-7B-Instruct-v0.1",
          "name": "Mistral 7B Instruct",
          "context_window": 8192,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "streaming"],
          "pricing": {
            "input_per_1k": 0.0002,
            "output_per_1k": 0.0002
          },
          "is_free": false
        },
        {
          "id": "codellama/CodeLlama-34b-Instruct-hf",
          "name": "CodeLlama 34B",
          "context_window": 16384,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "code", "streaming"],
          "pricing": {
            "input_per_1k": 0.0008,
            "output_per_1k": 0.0008
          },
          "is_free": false
        }
      ]
    },
    "replicate": {
      "name": "Replicate",
      "base_url": "https://api.replicate.com/v1",
      "env": ["REPLICATE_API_TOKEN"],
      "models": [
        {
          "id": "meta/llama-2-70b-chat",
          "name": "Llama 2 70B Chat",
          "context_window": 4096,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "streaming"],
          "pricing": {
            "input_per_1k": 0.0004,
            "output_per_1k": 0.0004
          },
          "is_free": false
        },
        {
          "id": "mistralai/mistral-7b-instruct-v0.1",
          "name": "Mistral 7B Instruct",
          "context_window": 8192,
          "max_output_tokens": 4096,
          "capabilities": ["chat", "streaming"],
          "pricing": {
            "input_per_1k": 0.0002,
            "output_per_1k": 0.0002
          },
          "is_free": false
        }
      ]
    },
    "gcp_vertex": {
      "name": "Google Cloud Vertex AI",
      "base_url": "https://{region}-aiplatform.googleapis.com/v1",
      "env": ["GOOGLE_APPLICATION_CREDENTIALS"],
      "models": [
        {
          "id": "gemini-1.5-pro",
          "name": "Gemini 1.5 Pro",
          "context_window": 1048576,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming", "vision"],
          "pricing": {
            "input_per_1k": 0.00125,
            "output_per_1k": 0.005
          },
          "is_free": false
        },
        {
          "id": "gemini-1.5-flash",
          "name": "Gemini 1.5 Flash",
          "context_window": 1048576,
          "max_output_tokens": 8192,
          "capabilities": ["chat", "code", "streaming", "vision"],
          "pricing": {
            "input_per_1k": 0.000075,
            "output_per_1k": 0.0003
          },
          "is_free": false
        },
        {
          "id": "palm-2-text-bison",
          "name": "PaLM 2 Text Bison",
          "context_window": 8192,
          "max_output_tokens": 1024,
          "capabilities": ["chat", "streaming"],
          "pricing": {
            "input_per_1k": 0.001,
            "output_per_1k": 0.002
          },
          "is_free": false
        }
      ]
    }
  }
}
